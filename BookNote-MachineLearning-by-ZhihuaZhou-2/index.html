<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/hikari_tairitsu/512x512.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/hikari_tairitsu/512x512.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/hikari_tairitsu/512x512.png">
  <meta name="google-site-verification" content="t21aSpg50tWVwctahE4QnLP2-fo79rclxw9e2TGaamw">
  <meta name="baidu-site-verification" content="to baidu automatically which is very helpful for SEO.">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"la-pluma.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":{"enable":true,"caption":false},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":{"gitalk":{"order":-1}},"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="有多个算法和参数生成的模型, 哪个才是好的模型?">
<meta property="og:type" content="article">
<meta property="og:title" content="读书笔记-机器学习 Ch2">
<meta property="og:url" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/index.html">
<meta property="og:site_name" content="LaPluma">
<meta property="og:description" content="有多个算法和参数生成的模型, 哪个才是好的模型?">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-1.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/spic2-2.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-2.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/tab2-1.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/spic2-1.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-3.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-4.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/tab2-2.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-5.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-6.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/spic2-3.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/spic2-4.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-7.png">
<meta property="og:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-9.png">
<meta property="article:published_time" content="2024-09-24T15:38:02.000Z">
<meta property="article:modified_time" content="2025-05-28T15:20:08.805Z">
<meta property="article:author" content="LaPluma">
<meta property="article:tag" content="读书笔记">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-1.png">

<link rel="canonical" href="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>读书笔记-机器学习 Ch2 | LaPluma</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="LaPluma" type="application/atom+xml">
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999;width:36px;height:36px}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">LaPluma</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Keep it simple and stupid.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/La-Pluma" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://la-pluma.github.io/BookNote-MachineLearning-by-ZhihuaZhou-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/hikari_tairitsu/avatar.jpg">
      <meta itemprop="name" content="LaPluma">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="LaPluma">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          读书笔记-机器学习 Ch2
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-09-24 23:38:02" itemprop="dateCreated datePublished" datetime="2024-09-24T23:38:02+08:00">2024-09-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-05-28 23:20:08" itemprop="dateModified" datetime="2025-05-28T23:20:08+08:00">2025-05-28</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">读书笔记-机器学习</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: inline;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>12k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>23 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>有多个算法和参数生成的模型, 哪个才是好的模型?</strong></p>
<span id="more"></span>
<p>
<font size = 5><b>目录</b></font>
</p>
<ul>
<li><a href="#chapter-2-模型评估与选择">Chapter 2: 模型评估与选择</a>
<ul>
<li><a href="#21-经验误差与过拟合">2.1 经验误差与过拟合</a></li>
<li><a href="#22-评估方法">2.2 评估方法</a>
<ul>
<li><a href="#221-留出法hold-out">2.2.1 留出法(Hold-Out)</a></li>
<li><a href="#222-交叉验证法cross-validation">2.2.2 交叉验证法(Cross
Validation)</a></li>
<li><a href="#223-自助法bootstapping">2.2.3
自助法(Bootstapping)</a></li>
<li><a href="#224-调参与最终模型">2.2.4 调参与最终模型</a></li>
</ul></li>
<li><a href="#23-性能度量">2.3 性能度量</a>
<ul>
<li><a href="#231-错误率与精度">2.3.1 错误率与精度</a></li>
<li><a href="#232-查准率precision-查全率recall-f1">2.3.2
查准率(Precision), 查全率(Recall), F1</a></li>
<li><a href="#233-roc与auc">2.3.3 ROC与AUC</a></li>
<li><a href="#234-代价敏感错误率与代价曲线">2.3.4
代价敏感错误率与代价曲线</a></li>
</ul></li>
<li><a href="#24-比较检验">2.4 比较检验</a>
<ul>
<li><a href="#241-假设检验">2.4.1 假设检验</a></li>
<li><a href="#242-多学习器比较">2.4.2 多学习器比较</a></li>
</ul></li>
<li><a href="#25-偏差与方差">2.5 偏差与方差</a></li>
</ul></li>
</ul>
<hr />
<h2 id="chapter-2-模型评估与选择">Chapter 2: 模型评估与选择</h2>
<h3 id="经验误差与过拟合">2.1 经验误差与过拟合</h3>
<ul>
<li><p><strong>错误率(Error Rate):</strong>
分类错误的样本数占样本总数的比例, 记样本数为<span
class="math inline">\(m\)</span>, <span
class="math inline">\(a\)</span>个错误分类的样本, 错误率 <span
class="math inline">\(E=\frac{a}{m}\)</span> .</p></li>
<li><p><strong>精度(Accuracy):</strong> <span class="math inline">\((1 -
\frac{a}{m}) \times 100\%\)</span> 称为精度, 即 "精度 = 1 -
错误率".</p></li>
<li><p><strong>误差(Error):</strong> 更一般地,
我们把<strong>学习器的实际预测输出</strong>与<strong>样本的真实输出</strong>之间的差异称为误差,
学习器在训练集上的误差称为 <strong>训练误差(Training
Error)/经验误差(Empirical Error)</strong>,
在新样本上的误差称为<strong>泛化误差(Generalization Error)</strong>.</p>
<blockquote>
<p><strong>Tips:</strong> 这里的误差均指<strong>误差期望</strong>.</p>
</blockquote></li>
</ul>
<p>尽管我们希望得到一个泛化误差小的学习器, 使得其在新样本上表现很好,
但我们并不能预测新样本, 因此我们只能尝试降低经验误差.
但经验误差很小的学习器往往在泛化误差的表现上都很糟糕.
这样的学习器发生了<strong>过拟合</strong>.</p>
<ul>
<li><p><strong>过拟合(Overfitting):</strong>
学习器可能将训练样本自身的一些特点当作了所有潜在样本都具有的一般性质,
导致泛化能力下降的现象.</p></li>
<li><p><strong>欠拟合(Underfitting):</strong> 与过拟合相对,
指对训练样本的一般性质尚未学好.</p></li>
</ul>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-1.png" class="" title="pic2-1">
<blockquote>
<p><strong>Tips:</strong> 导致过拟合的原因很多,
最常见的原因是学习能力过强; 欠拟合则相反, 因为学习能力低下.
欠拟合容易克服, 但过拟合很难解决, 且过拟合无法彻底避免.</p>
</blockquote>
<ul>
<li><strong>模型选择(Model Selection):</strong> 在实际中,
面对同一个问题, 往往有多种学习算法可以选择,
参数配置也会对模型产生影响.</li>
</ul>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/spic2-2.png" class="" title="spic2-2">
<h3 id="评估方法">2.2 评估方法</h3>
<p>通常我们可以通过实验测试对学习器的泛化误差进行评估,
使用<strong>测试集(Testing Set)</strong>测试学习器对新样本的判别能力,
以测试集上<strong>测试误差(Testing Error)</strong>作为泛化误差的近似.
但需要注意的是, 测试集应尽可能与训练集互斥.</p>
<blockquote>
<p>假设我们有且只有一个包含<span
class="math inline">\(m\)</span>个样例的数据集<span
class="math inline">\(D = \{(x_1,y_1),(x_2,y_2), ...,
(x_m,y_m)\}\)</span>, 既要训练, 又要测试, 这样就需要对<span
class="math inline">\(D\)</span>进行适当处理, 从中产生
<strong>训练集</strong> <span class="math inline">\(S\)</span>和
<strong>测试集</strong> <span class="math inline">\(T\)</span>.</p>
</blockquote>
<h4 id="留出法hold-out">2.2.1 留出法(Hold-Out)</h4>
<p>留出法的思路很简单, 直接将数据集<span
class="math inline">\(D\)</span>划分成两个互斥的集合, 即<span
class="math inline">\(D = S \cup T, S \cap T = \emptyset\)</span>.</p>
<p>使用留出法时需要注意训练集和测试集的划分需要保持数据分布一致性,
避免因数据划分引入额外偏差对结果产生影响.
同时单次留出法得到的估计往往并不够准确可靠, 一般采用若干次随机划分,
重复进行实验评估取平均值作为留出法评估结果. 关于划分比例, 通常取2/3 ~
4/5的样本用于训练, 其余用于测试.</p>
<h4 id="交叉验证法cross-validation">2.2.2 交叉验证法(Cross
Validation)</h4>
<p>交叉验证法可以看作是一种具体的留出法, 其方法过程是:</p>
<p>先将数据集<span class="math inline">\(D\)</span>划分为<span
class="math inline">\(k\)</span>个大小相似的互斥子集, <span
class="math inline">\(D = D_1 \cup D_2 \cup ... \cup D_k, D_i \cap D_j =
\emptyset (i \neq j)\)</span>, 子集<span
class="math inline">\(D_i\)</span>通过保留类别比例的<strong>分层采样(Stratified
Sampling)</strong>来尽可能保持数据分布一致性.</p>
<p>接下来每次取<span class="math inline">\(k-1\)</span>个子集作为训练集,
余下一个作为测试集, 进行<span
class="math inline">\(k\)</span>次训练和测试, 最终结果取<span
class="math inline">\(k\)</span>个结果的均值.</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-2.png" class="" title="pic2-2">
<p>显然交叉验证法评估结果的<strong>稳定性(Stability)</strong>和<strong>保真性(Fidelity)</strong>与<span
class="math inline">\(k\)</span>的取值强相关.
故而交叉验证法又称<strong>k折交叉验证(k-fold Cross Validation)</strong>.
最常见的取值是 <span class="math inline">\(k=10\)</span>.</p>
<p>由于<span class="math inline">\(D\)</span>的<span
class="math inline">\(k\)</span>划分不唯一, k折交叉验证通常也要重复多次,
记为<span class="math inline">\(p\)</span>, 最终结果取这<span
class="math inline">\(p\)</span>次k折交叉验证结果的均值.</p>
<p><strong>留一法(Leave-One-Out, LOO)</strong>, <span
class="math inline">\(|D| = m\)</span>, 则令<span
class="math inline">\(k = m\)</span> 就得到了留一法.</p>
<p>留一法的优势是不受样本划分影响(有且仅有一种划分方式), 训练集仅比<span
class="math inline">\(D\)</span>少一个样本,
绝大多数情况下留一法中被评估的模型与期望用<span
class="math inline">\(D\)</span>训练的模型相似.
因此认为留一法评估结果较为准确. 缺点是当<span
class="math inline">\(m\)</span>较大时, 计算开销过大以致无法接受.</p>
<h4 id="自助法bootstapping">2.2.3 自助法(Bootstapping)</h4>
<p>留出法和交叉验证法都保留了一部分样本用于测试,
因此实际评估的模型所使用的训练集比<span
class="math inline">\(D\)</span>小,
必然会引入一些因训练样本规模不同而导致的估计偏差.
留一法的计算复杂度又太高了. 自助法提供了一个较好的解决方案.</p>
<p>自助法直接以 <strong>自助采样法(Bootstrap Sampling)</strong> 为基础.
给定包含<span class="math inline">\(m\)</span>个样本的数据集<span
class="math inline">\(D\)</span>, 对其进行采样产生数据集<span
class="math inline">\(D&#39;\)</span>. 采样过程每次随即从<span
class="math inline">\(D\)</span>中挑选一个样本, 将拷贝放入<span
class="math inline">\(M&#39;\)</span>
<strong>(意味着下次采样该样本仍有可能被采样到)</strong>. 重复该过程<span
class="math inline">\(m\)</span>次, 得到了包含<span
class="math inline">\(m\)</span>个样本的数据集<span
class="math inline">\(D&#39;\)</span>.</p>
<blockquote>
<p><strong>Tips:</strong> 此处"自助"为意译,
称<strong>可重复采样/有放回采样</strong>更符合其原理.</p>
</blockquote>
<p>不难看出, 可能存在部分样本被多次采样到, 部分样本未被采样到.
我们关注某个样本在<span
class="math inline">\(m\)</span>次中未被采样的概率,有</p>
<p><span class="math display">\[\begin{equation}
\lim_{m \rightarrow \infty}(1 - \frac{1}{m})^m  = \frac{1}{e} \approx
0.368 \tag{2.1}
\end{equation}\]</span></p>
<p>通过自主采样, 初始数据集<span
class="math inline">\(D\)</span>中约有<span
class="math inline">\(36.8\%\)</span>的样本未出现在采样数据集<span
class="math inline">\(D&#39;\)</span>中, 将<span
class="math inline">\(D&#39;\)</span>作为训练集, <span
class="math inline">\(D \backslash D&#39;\)</span>作为测试集.
这样的测试结果称为<strong>包外估计(Out-Of-Bagestimate)</strong>.</p>
<p>自助法在数据集较小, 难以有效划分训练和测试集的时候具有优势.
但自助法产生的数据集改变了初始数据集的分布, 会引入估计误差.
初始数据集较大时更常用留出法和交叉验证法.</p>
<h4 id="调参与最终模型">2.2.4 调参与最终模型</h4>
<p><strong>参数(Parameter)</strong>和<strong>调参(Parameter
Tuning)</strong>释义见名称.</p>
<blockquote>
<p><strong>Tips:</strong> 机器学习常涉及两类参数:
算法参数和模型参数.</p>
</blockquote>
<ul>
<li><p><strong>验证集(Validation Set):</strong>
模型评估与选择中用于评估测试的数据集常称为验证集.</p>
<blockquote>
<p><strong>Additonal:</strong> 关于训练集, 测试集和验证集的区别,
笔者在此参考<a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/98532085"><strong>[知乎|训练集、验证集、测试集]</strong></a></p>
</blockquote></li>
</ul>
<h3 id="性能度量">2.3 性能度量</h3>
<ul>
<li><strong>性能度量(Performance Measure):</strong>
衡量模型泛化能力的评价标准. 显然该标准取决于任务需求.</li>
</ul>
<p>以预测任务为例, 给定样例集<span class="math inline">\(D =
\{(\boldsymbol{x_1}, y_1), (\boldsymbol{x_2}, y_2), ...,
(\boldsymbol{x_m}, y_m)\}\)</span>, 其中<span
class="math inline">\(y_i\)</span>是<span
class="math inline">\(\boldsymbol{x_i}\)</span>的真实标记,
评估学习器<span class="math inline">\(f\)</span>的性能,
需要比较预测结果<span class="math inline">\(f(x)\)</span>与真实标记<span
class="math inline">\(y\)</span>.</p>
<p>回归任务常用性能度量<strong>均方误差(Mean Squared Error)</strong></p>
<p><span class="math display">\[\begin{equation}
E(f;D) = \frac{1}{m} \sum_{i=1}^{m}(f(\boldsymbol{x_i}) - y_i)^2
\tag{2.2}
\end{equation}\]</span></p>
<p>更一般地, 对于数据分布<span
class="math inline">\(\mathcal{D}\)</span>和概率密度函数<span
class="math inline">\(p(\cdot)\)</span>, 均方误差描述为</p>
<p><span class="math display">\[\begin{equation}
E(f;\mathcal{D}) = \int_{x \sim \mathcal{D}}^{}(f(\boldsymbol{x}) - y)^2
p(\boldsymbol{x}) d\boldsymbol{x} \tag{2.3}
\end{equation}\]</span></p>
<h4 id="错误率与精度">2.3.1 错误率与精度</h4>
<p>错误率和精度是分类任务中最常用的两种性能度量.</p>
<p>对于样例集<span class="math inline">\(\mathcal{D}\)</span>,
错误率和精度定义为</p>
<p><span class="math display">\[\begin{equation}
E(f;D) = \frac{1}{m} \sum_{i=1}^{m}\mathbb{I}(f(\boldsymbol{x_i}) \neq
y_i) \tag{2.4}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
acc(f;D) = \frac{1}{m} \sum_{i=1}^{m}\mathbb{I}(f(\boldsymbol{x_i}) =
y_i) = 1 - E(f;D) \tag{2.5}
\end{equation}\]</span></p>
<p>对于数据分布<span
class="math inline">\(\mathcal{D}\)</span>和概率密度函数<span
class="math inline">\(p(\cdot)\)</span>, 错误率和精度定义为</p>
<p><span class="math display">\[\begin{equation}
E(f;\mathcal{D}) = \int_{x \sim
\mathcal{D}}^{}\mathbb{I}(f(\boldsymbol{x}) \neq y) p(\boldsymbol{x})
d\boldsymbol{x} \tag{2.6}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
acc(f;\mathcal{D}) = \int_{x \sim
\mathcal{D}}^{}\mathbb{I}(f(\boldsymbol{x}) = y) p(\boldsymbol{x})
d\boldsymbol{x} = 1 - E(f;\mathcal{D}) \tag{2.7}
\end{equation}\]</span></p>
<h4 id="查准率precision-查全率recall-f1">2.3.2 查准率(Precision),
查全率(Recall), F1</h4>
<p>有时我们更关心模型的正确率,
比如说"挑选出来的瓜有多少是好瓜","有多少好瓜被挑选出来了",
查准率和查全率更适合用来度量.</p>
<p>对于二分类问题, 我们有<strong>混淆矩阵(Confusion Matrix)</strong></p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/tab2-1.png" class="" title="tab2-1">
<p>定义查准率<span class="math inline">\(P\)</span>, 查全率<span
class="math inline">\(R\)</span></p>
<p><span class="math display">\[\begin{equation}
P = \frac{TP}{TP + FP}\tag{2.8}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
P = \frac{TP}{TP + FN}\tag{2.9}
\end{equation}\]</span></p>
<blockquote>
<p><strong>Tips:</strong> 自然语言解释就是,
查准率是在预测正确中实际正确的比率,
查全率是在实际正确中预测正确的比率.</p>
</blockquote>
<p>查准率和查全率是一对矛盾的度量, 二者负相关.
是<strong>sound</strong>和<strong>complete</strong>的关系</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/spic2-1.png" class="" title="spic2-1">
<blockquote>
<p><strong>Tips:</strong> 该图片截选自NJU软件分析课件,
<del>ly和tt老师应该不会在意吧(雾)</del></p>
<p>课程地址链接<a
target="_blank" rel="noopener" href="https://tai-e.pascal-lab.net/lectures.html"><strong>[Static
Program Analysis]</strong></a></p>
</blockquote>
<p>查准率和查全率的关系可以用<strong>P-R图</strong>表示</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-3.png" class="" title="pic2-3">
<ul>
<li><strong>平衡点(Break-Even Point, BEP):</strong> <span
class="math inline">\(P=R\)</span>时的取值,
可基于BEP评估两个学习器的优劣, 如图2-3, 可认为<span
class="math inline">\(A&gt;B&gt;C\)</span></li>
</ul>
<p>比BEP更常用的是<span class="math inline">\(F1\)</span>度量定义为</p>
<p><span class="math display">\[\begin{equation}
F1 = \frac{2 \times P \times R}{P + R} = \frac{2 \times TP}{样例总数 +
TP - TN}\tag{2.10}
\end{equation}\]</span></p>
<p><span class="math inline">\(F_{\beta}\)</span>是<span
class="math inline">\(F_1\)</span>的一般形式, 定义为</p>
<p><span class="math display">\[\begin{equation}
F_{\beta} = \frac{(1 + \beta^2) \times P \times R}{(\beta^2 \times P) +
R}\tag{2.11}
\end{equation}\]</span></p>
<p>其中<span class="math inline">\(\beta &gt;
0\)</span>度量了查全率对查准率的相对重要性, <span
class="math inline">\(\beta = 1\)</span>时退化为<span
class="math inline">\(F_1\)</span>, <span class="math inline">\(\beta
&gt; 1\)</span>时查全率影响更大, <span class="math inline">\(\beta &lt;
1\)</span>时查准率影响更大.</p>
<blockquote>
<p><strong>Tips:</strong></p>
<p><span class="math inline">\(F_1\)</span>基于调和平均定义, <span
class="math inline">\(\frac{1}{F_1} = \frac{1}{2} \cdot (\frac{1}{P} +
\frac{1}{R})\)</span>.</p>
<p><span class="math inline">\(F_\beta\)</span>基于加权调和平均定义,
<span class="math inline">\(\frac{1}{F_\beta} = \frac{1}{1 + \beta^2}
\cdot (\frac{1}{P} + \frac{\beta^2}{R})\)</span></p>
</blockquote>
<p>若在n个二分类混淆矩阵上考察准确率和查全率,
我们有<strong>macro</strong>和<strong>micro</strong>两种选择.</p>
<p>对于<strong>宏(macro)</strong>, 在各个混淆矩阵上分别计算<span
class="math inline">\(P\)</span>和<span
class="math inline">\(R\)</span>,
再取平均.得到<strong>宏查准率(macro-P)</strong>,
<strong>宏查全率(macro-R)</strong>, <strong>宏F1(macro-F1)</strong></p>
<p><span class="math display">\[\begin{equation}
macro\text{-}P = \frac{1}{n} \sum_{i=1}^{n} P_i\tag{2.12}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
macro\text{-}R = \frac{1}{n} \sum_{i=1}^{n} R_i\tag{2.13}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
macro\text{-}F1 = \frac{2 \times macro\text{-}P \times
macro\text{-}R}{macro\text{-}P + macro\text{-}R}\tag{2.14}
\end{equation}\]</span></p>
<p>对于<strong>微(micro)</strong>, 先平均混淆矩阵得到$, , , $,
再计算出<strong>微查准率(micro-P)</strong>,
<strong>微查全率(micro-R)</strong>, <strong>微F1(micro-F1)</strong></p>
<p><span class="math display">\[\begin{equation}
micro\text{-}P =
\frac{\overline{TP}}{\overline{TP}+\overline{FP}}\tag{2.15}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
micro\text{-}R = \frac{\overline{TP}}{\overline{TP}+\overline{FN}}
\tag{2.16}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
micro\text{-}F1 = \frac{2 \times micro\text{-}P \times
micro\text{-}R}{micro\text{-}P + micro\text{-}R}\tag{2.17}
\end{equation}\]</span></p>
<h4 id="roc与auc">2.3.3 ROC与AUC</h4>
<p>现重新考虑查准率和查全率, 首先我们来看看学习器如何给正/反的分类.</p>
<p>很多学习器为测试样本产生一个实值或概率预测,
将预测值与<strong>分类阈值(Threshold)</strong>比较, 大于阈值则为正类,
否则为反类. 根据该实值或概率预测进行排序, 概率高的在前, 概率低的在后,
则这个分类阈值就是<strong>截断点(Cut Point)</strong>, 前一部分为正例,
后一部分为负例.</p>
<p>不难得到以下结论: 截断点越靠前, 查准率增高而查全率降低; 截断点越靠后,
查准率降低而查全率增高. 同时,
排序质量越好的学习器"在一般情况下"泛化性能越好,
ROC基于此度量模型的泛化能力.</p>
<p><strong>受试者工作特征(Receiver Operating Characteristic,
ROC)</strong>, 根据学习器的预测结果对样例进行排序,
顺序逐个把样本作为正例进行预测(选择不同的截断点),计算
<strong>真正例率(True Positive Rate, TPR)</strong>,
<strong>假正例率(False Positive Rate, FPR)</strong> 作为纵横轴.</p>
<p><span class="math display">\[\begin{equation}
TPR = \frac{TP}{TP + FN}
\tag{2.18}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
FPR = \frac{FP}{TN + FP}
\tag{2.19}
\end{equation}\]</span></p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-4.png" class="" title="pic2-4">
<p>对角线对应随即猜测模型, 点(0, 1)对应所有正例在负例前的理想模型.</p>
<ul>
<li><strong>AUC(Area Under ROC Curve):</strong> ROC曲线下面积.
为依据两个模型绘制的ROC曲线比较两个模型的优劣而引入.</li>
</ul>
<p>对于离散样本, 计算AUC:</p>
<p><span class="math display">\[\begin{equation}
AUC = \frac{1}{2} \sum^{m - 1}_{i=1}(x_{i+1} - x_i)\cdot(y_i + y_{i + 1}
)
\tag{2.19}
\end{equation}\]</span></p>
<p>形式化上AUC度量排序质量, 记有<span
class="math inline">\(m^+\)</span>个正例, <span
class="math inline">\(m^-\)</span>个反例, 令<span
class="math inline">\(D^+\)</span>为正例集合, <span
class="math inline">\(D^-\)</span>为负例集合,
定义排序<strong>损失(loss):</strong></p>
<p><span class="math display">\[\begin{equation}
\mathscr{l}_{rank} = \frac{1}{m^+ m^-}\sum_{x^+ \in D^+} \sum_{m^- \in
D^-}\left(\mathbb{I}(f(x^+)&lt;f(x^-)) + \frac{1}{2} \mathbb{I}(f(x^+)=
f(x^-))\right)
\tag{2.21}
\end{equation}\]</span></p>
<p>如何理解这个式子? 考虑每一对正反例, 若正例小于反例记一个"罚分",
相等则记半个. 不难看出, 对于每个正例/负例, 可能造成的"罚分"与其"位置",
越"错误"的位置会引起越多的"罚分", 这与AUC计算过程及其相似. 实际上, <span
class="math inline">\(\mathscr{l}_{rank}\)</span>对应ROC曲线上方的面积,
有</p>
<p><span class="math display">\[\begin{equation}
AUC = 1 - \mathscr{l}_{rank}
\tag{2.22}
\end{equation}\]</span></p>
<h4 id="代价敏感错误率与代价曲线">2.3.4 代价敏感错误率与代价曲线</h4>
<p>为权衡不同类型错误所造成的不同损失,
我们为错误赋予<strong>非均等代价(UnEqual Cost)</strong>.</p>
<p>以二分类为例, <strong>代价矩阵(Cost Matrix)</strong>如下:</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/tab2-2.png" class="" title="tab2-2">
<p>若将0类记为正例, 1类记为负例, 定义<span class="math inline">\(D^+,
D^-\)</span>, <strong>代价敏感(Cost-Sensitive)</strong> 错误率为</p>
<p><span class="math display">\[\begin{equation}
E(f;D;cost) = \frac{1}{m} \left(\sum_{\boldsymbol{x}_i \in D^+}
\mathbb{I}(f(\boldsymbol{x}_i) \neq y_i) \times cost_{01} +
\sum_{\boldsymbol{x}_i \in D^-} \mathbb{I}(f(\boldsymbol{x}_i) \neq y_i)
\times cost_{10}\right)
\tag{2.23}
\end{equation}\]</span></p>
<p>非均等情况下, <strong>代价曲线(Cost
Curve)</strong>可以解决ROC曲线不能反映出学习器的期望<strong>总体代价(Total
Cost)</strong>问题.</p>
<p>其横轴是取值为<span
class="math inline">\([0,1]的\)</span>正例概率代价, 其中<span
class="math inline">\(p\)</span>为样例是正例的概率</p>
<p><span class="math display">\[\begin{equation}
P(+)cost=\frac{p \times cost_{01}}{p \times cost_{01} + (1 - p) \times
cost_{10}}
\tag{2.24}
\end{equation}\]</span></p>
<p>纵轴是取值为<span
class="math inline">\([0,1]\)</span>的归一化代价,FPR为假正例率,
FNR为假反例率</p>
<p><span class="math display">\[\begin{equation}
cost_{norm} = \frac{FNR \times p \times cost_{01} + FPR \times (1 - p)
\times cost_{10}}{p \times cost_{01} + (1 - p) \times cost_{10}}
\tag{2.25}
\end{equation}\]</span></p>
<p>绘制代价曲线时, ROC曲线上每个点对应代价平面上的一条线段,
设ROC点坐标为<span class="math inline">\((FPR, TPR)\)</span>,
然后在代价平面上绘制一条从<span class="math inline">\((0,
FPR)\)</span>到<span class="math inline">\((1, FNR)\)</span>的线段,
线段下面积代表了该条件下的期望总体代价.如此为每个点绘制线段, 取线段下界,
围成面积即为在所有条件下学习器的总体期望代价.</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-5.png" class="" title="pic2-5">
<blockquote>
<p><strong>Addtional:</strong> 如何理解代价曲线?</p>
<p>笔者在此给出一篇参考<a
target="_blank" rel="noopener" href="https://www.zhihu.com/question/63492375"><strong>[知乎|代价曲线的理解]</strong></a>.这篇参考中对大部分问题给到了解释.</p>
<p>在此额外补充一点困惑笔者许久的问题, 每一条线段代表什么?</p>
<p>每一条线段代表当前<strong>阈值</strong>条件下,
对不同样本集的期望代价. 具体来说,
是以FPR和FNR为预测值对不同样本集的预测.</p>
</blockquote>
<h3 id="比较检验">2.4 比较检验</h3>
<p><strong>统计假设检验(Hypothesis Test)</strong>
为比较学习器性能提供了重要依据. 本节默认以错误率为性能度量, 用<span
class="math inline">\(\epsilon\)</span>表示.</p>
<h4 id="假设检验">2.4.1 假设检验</h4>
<p>现实中我们无法知道学习器的泛化错误率 <span
class="math inline">\(\epsilon\)</span>, 只能获知其测试错误率 <span
class="math inline">\(\hat{\epsilon}\)</span>.
常用测试错误率估推出泛化错误率.</p>
<p>对于 <span class="math inline">\(m\)</span> 个测试样本,
如果测试错误率为 <span class="math inline">\(\hat{\epsilon}\)</span>,
则被误分类的样本数量 <span class="math inline">\(m&#39;=\hat{\epsilon}
\times m\)</span>, 假定测试样本从样本总体分布中独立采样获得,
由<strong>二项(Binomial)分布</strong>, 泛化错误率为 <span
class="math inline">\(\hat{\epsilon}\)</span> 的学习器恰有 <span
class="math inline">\(m&#39;\)</span> 个样本被误分类的概率是 <span
class="math inline">\(\binom{m}{m&#39;}\epsilon^{m&#39;}(1-\epsilon)^{m-m&#39;}\)</span>
. 同时, 这也表示泛化错误率为 <span
class="math inline">\(\epsilon\)</span> 的学习器在<span
class="math inline">\(m\)</span>个样本上测试得到测试错误率为 <span
class="math inline">\(\hat{\epsilon}\)</span> 的概率:</p>
<p><span class="math display">\[\begin{equation}
P(\hat{\epsilon};\epsilon)=\binom{m}{\hat{\epsilon} \times m}
\epsilon^{\hat{\epsilon} \times m} (1 - \epsilon)^{m - \hat{\epsilon}
\times m}
\tag{2.26}
\end{equation}\]</span></p>
<p>由二项分布性质, 或者计算 <span
class="math inline">\(P(\hat{\epsilon};\epsilon)\)</span> 对 <span
class="math inline">\(\epsilon\)</span> 的偏导, 可以知道 <span
class="math inline">\(P(\hat{\epsilon};\epsilon)\)</span> 在 <span
class="math inline">\(\epsilon = \hat{\epsilon}\)</span> 时最大, <span
class="math inline">\(|\epsilon - \hat{\epsilon}|\)</span> 增大时 <span
class="math inline">\(P(\hat{\epsilon};\epsilon)\)</span> 减小.</p>
<p>若取 <span class="math inline">\(m=10, \epsilon = 0.3\)</span>,
示意图如2.6所示.</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-6.png" class="" title="pic2-6">
<blockquote>
<p><strong>Tips:</strong>
<del>死去的《概率论与数理统计》突然复活起来攻击我</del>, 推荐复习笔记<a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/243215469"><strong>[知乎|概率论与数理统计复习整理]</strong></a>.</p>
</blockquote>
<p>由<strong>二项检验(Binomial Test)</strong>, 考虑假设<span
class="math inline">\(\epsilon \leq \epsilon_0\)</span>, 在 <span
class="math inline">\(1 - \alpha\)</span>
的概率内能观测到的最大错误率为</p>
<p><span class="math display">\[\begin{equation}
\bar{\epsilon} = \min \epsilon \ \ \text{s.t.} \ \ \sum_{i = \epsilon
\times m + 1}^{m} \binom{m}{i}\epsilon_0^i (1 - \epsilon_0)^{m - i} &lt;
\alpha
\tag{2.27}
\end{equation}\]</span></p>
<p>其中 <span class="math inline">\(1-\alpha\)</span>
为<strong>置信度(Confidence)</strong>, 直观上对应图2.6的非阴影部分;
"s.t."是"subject to", 使左边式子在右边式子条件满足时成立.</p>
<p>若测试错误率 <span class="math inline">\(\hat{\epsilon}\)</span>
大于临界值 <span class="math inline">\(\bar{\epsilon}\)</span>,
由二项检验, 我们可以认为在 <span class="math inline">\(\alpha\)</span>
的显著度下, 假设 <span class="math inline">\(\epsilon \leq
\hat{\epsilon}\)</span> 不能被拒绝, 即能以 <span
class="math inline">\(1-\alpha\)</span> 的置信度认为,
学习器的泛化错误率不高于 <span
class="math inline">\(\epsilon_0\)</span>; 否则可以拒绝假设, 在 <span
class="math inline">\(\alpha\)</span>
的显著度下可认为学习器的泛化错误率大于 <span
class="math inline">\(\epsilon_0\)</span>.</p>
<p>在通过多次测试中中我们会获得多个测试错误率,
此时可使用<strong>t检验(t-test)</strong>.</p>
<p>设<span class="math inline">\(k\)</span>个错误率 <span
class="math inline">\(\hat{\epsilon_1}, \hat{\epsilon_2}, ...,
\hat{\epsilon_k}\)</span>, 则平均错误率 <span
class="math inline">\(\mu\)</span>, 方差 <span
class="math inline">\(\sigma^2\)</span> 为</p>
<p><span class="math display">\[\begin{equation}
\mu = \frac{1}{k} \sum_{i=1}^k \hat{\epsilon_i}
\tag{2.28}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\sigma^2=\frac{1}{k-1} \sum^{k}_{i=1}(\hat{\epsilon_i} - \mu)^2
\tag{2.29}
\end{equation}\]</span></p>
<p><span class="math inline">\(k\)</span> 个测试错误率可看作是泛化错误率
<span class="math inline">\(\epsilon_0\)</span> 的独立采样, 则变量</p>
<p><span class="math display">\[\begin{equation}
\tau_t=\frac{\sqrt{k} (\mu - \epsilon_0)}{\sigma}
\tag{2.30}
\end{equation}\]</span></p>
<p>服从自由度为 <span class="math inline">\(k-1\)</span> 的 <span
class="math inline">\(t\)</span> 分布.</p>
<blockquote>
<p><strong>Addtional:</strong> <strong>基础知识补充</strong></p>
<p><span class="math inline">\(\chi^2\)</span> 分布: <span
class="math inline">\(X_1, X_2, ..., X_n\)</span> 为独立同分布随机变量,
服从 <span class="math inline">\(N(0, 1)\)</span>, 则 <span
class="math inline">\(\chi^2_n = \sum_{i=1}^n X^2_i\)</span>
为服从自由度为 <span class="math inline">\(n\)</span> 的 <span
class="math inline">\(\chi^2\)</span> 分布</p>
<p><span class="math inline">\(t\)</span> 分布: <span
class="math inline">\(X \sim N(0,1), Y \sim \chi^2(n)\)</span>, <span
class="math inline">\(X,Y\)</span> 独立, 称 <span
class="math inline">\(T = \frac{X}{\sqrt{\frac{Y}{n}}}\)</span>
为服从自由度为 <span class="math inline">\(n\)</span> 的 <span
class="math inline">\(t\)</span> 分布.</p>
</blockquote>
<blockquote>
<p><strong>Tips:</strong> <strong>推导补充</strong></p>
<p>原书中没有关于这个<span
class="math inline">\(\tau_t\)</span>服从<span
class="math inline">\(t\)</span>分布的推导, 笔者在此给出补充.</p>
<p>假设<span
class="math inline">\(X_1,X_2,...X_n\)</span>是来自正态总体<span
class="math inline">\(N(\mu,\sigma^2)\)</span>的样本.
我们有以下重要统计量:</p>
<p><span class="math display">\[
\begin{align}
\nonumber\text{样本均值}&amp; \ \bar{X}=\frac{1}{n}\sum_{i=1}^n &gt;X_i
\\
\nonumber\text{样本方差}&amp; \
S^2=\frac{1}{n-1}\sum_{i-1}^{n}(X_i-\bar{X})^2
\end{align}
\]</span></p>
<p>我们有几个重要结论:</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/spic2-3.png" class="" title="spic2-3">
<p>故而有推论:</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/spic2-4.png" class="" title="spic2-4">
</blockquote>
<p>对假设<span
class="math inline">\(\mu=\epsilon_0\)</span>和显著度<span
class="math inline">\(\alpha\)</span>, 可以算出临界值——在<span
class="math inline">\(1-\alpha\)</span>内能观测到的最大错误率.
考虑<strong>双边假设(Two-Tailed)</strong>, 若<span
class="math inline">\(\tau_t\)</span>位于临界区<span
class="math inline">\([t_{-\alpha/2},t_{\alpha/2}]\)</span>内(如图2.7所示),
则不能拒绝假设<span class="math inline">\(\mu=\epsilon_0\)</span>.
我们可以认为泛化错误率为<span
class="math inline">\(\epsilon_0\)</span>.</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-7.png" class="" title="pic2-7">
<h4 id="多学习器比较">2.4.2 多学习器比较</h4>
<p>笔者对这部分不做过多记录, 翻阅原书该部分即可.</p>
<p>对于两个学习器,我们有</p>
<ul>
<li>交叉验证t检验(基于成对t 检验)</li>
<li>McNember检验(基于列联表，卡方检验)</li>
</ul>
<p>对于多个学习器,我们有</p>
<ul>
<li>Friedman检验(基于序值，F检验; 判断”是否都相同”)</li>
<li>Nemenyi后续检验(基于序值，进一步判断两两差别)</li>
</ul>
<h3 id="偏差与方差">2.5 偏差与方差</h3>
<ul>
<li><strong>偏差-方差分解(Bias-variance Decomposition)</strong></li>
</ul>
<p>对测试样本<span class="math inline">\(\boldsymbol{x}\)</span>,
令<span class="math inline">\(y_D\)</span>为<span
class="math inline">\(\boldsymbol{x}\)</span>在数据集的集中标记, <span
class="math inline">\(y\)</span>为<span
class="math inline">\(\boldsymbol{x}\)</span>的真实标记, <span
class="math inline">\(f(\boldsymbol{x};D)\)</span>为训练集<span
class="math inline">\(D\)</span>上的学得模型<span
class="math inline">\(f\)</span>在<span
class="math inline">\(\boldsymbol{x}\)</span>上的预测输出.</p>
<p>以回归算法为例, 我们有如下定义(符号定义见<a
target="_blank" rel="noopener" href="http://localhost:4000/2024/09/18/BookNote-MachineLearning-by-ZhihuaZhou-1/#chapter-0-%E4%B8%BB%E8%A6%81%E7%AC%A6%E5%8F%B7%E8%A1%A8"><strong>[Lapluma|读书笔记-机器学习
Ch0-Ch1]</strong></a>):</p>
<p>学习算法的期望预测.</p>
<p><span class="math display">\[\begin{equation}
\bar{f}(\boldsymbol{x})=\mathbb{E}_D[f(\boldsymbol{x};D)]
\tag{2.37}
\end{equation}\]</span></p>
<p>使用样本数相同的不同训练集产生的方差,
度量了同样大小的训练集变动导致的学习性能变化,
刻画了数据扰动造成的影响.</p>
<p><span class="math display">\[\begin{equation}
\mathcal{var}(\boldsymbol{x})=\mathbb{E}_D[(f(\boldsymbol{x};D)-\bar{f}(x))^2]
\tag{2.38}
\end{equation}\]</span></p>
<p>噪声, 在当前学习任务上任何学习算法所能达到的期望泛化误差下界,
刻画了学习问题本身的难度.</p>
<p><span class="math display">\[\begin{equation}
\varepsilon^2=\mathbb{E}_D[(y_D-y)^2]
\tag{2.39}
\end{equation}\]</span></p>
<p>期望输出与真实标记的差别称为偏差,
度量了学习算法的期望预测与真是结果的偏离程度,
刻画了学习算法本身的拟合能力.</p>
<p><span class="math display">\[\begin{equation}
\mathcal{bias}^2(\boldsymbol{x})=(\bar{f}(\boldsymbol{x})-y)^2
\tag{2.40}
\end{equation}\]</span></p>
<p>便于讨论,我们假定噪声期望为0, 即<span
class="math inline">\(\mathbb{E}_D[y_D-y]=0\)</span>,
对期望泛化误差进行分解(推导略, 见原书), 有</p>
<p><span class="math display">\[\begin{equation}
E(f;D)=bias^2(\boldsymbol{x})+var(\boldsymbol{x})+\varepsilon ^2
\tag{2.42}
\end{equation}\]</span></p>
<p>即泛化误差可以分解为偏差, 方差和噪声之和.</p>
<p>一般来说, 偏差和方差存在冲突, 称为<strong>偏差-方差窘境(Bias-Variance
Dilemma)</strong>,见图2-9.</p>
<img src="/BookNote-MachineLearning-by-ZhihuaZhou-2/pic2-9.png" class="" title="pic2-9">
<p>训练不足时, 学习器拟合能力不足,
训练数据的扰动不足以使学习器产生显著变化,
此时偏差主导了泛化错误率;训练程度加深, 学习器拟合能力增强,
训练数据发生的扰动被学习器学习到, 方差逐渐主导了泛化错误率;训练充足后,
学习器拟合能力非常强. 训练数据发生轻微扰动都会导致学习器发生显著变化,
此时训练数据自身,非全局的性质被学习器学习, 发生过拟合.</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" rel="tag"># 读书笔记</a>
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"># 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/BookNote-DesignPatterns-by-JieCheng-2/" rel="prev" title="读书笔记-大话设计模式 Ch1-Ch5">
      <i class="fa fa-chevron-left"></i> 读书笔记-大话设计模式 Ch1-Ch5
    </a></div>
      <div class="post-nav-item">
    <a href="/LabRecord-SPA-A1/" rel="next" title="NJU静态分析|A1-Live Variable Analysis">
      NJU静态分析|A1-Live Variable Analysis <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#chapter-2-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9"><span class="nav-number">1.</span> <span class="nav-text">Chapter 2: 模型评估与选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%8F%E9%AA%8C%E8%AF%AF%E5%B7%AE%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88"><span class="nav-number">1.1.</span> <span class="nav-text">2.1 经验误差与过拟合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="nav-number">1.2.</span> <span class="nav-text">2.2 评估方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%95%99%E5%87%BA%E6%B3%95hold-out"><span class="nav-number">1.2.1.</span> <span class="nav-text">2.2.1 留出法(Hold-Out)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%B3%95cross-validation"><span class="nav-number">1.2.2.</span> <span class="nav-text">2.2.2 交叉验证法(Cross
Validation)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%87%AA%E5%8A%A9%E6%B3%95bootstapping"><span class="nav-number">1.2.3.</span> <span class="nav-text">2.2.3 自助法(Bootstapping)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%B0%83%E5%8F%82%E4%B8%8E%E6%9C%80%E7%BB%88%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.2.4.</span> <span class="nav-text">2.2.4 调参与最终模型</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"><span class="nav-number">1.3.</span> <span class="nav-text">2.3 性能度量</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%94%99%E8%AF%AF%E7%8E%87%E4%B8%8E%E7%B2%BE%E5%BA%A6"><span class="nav-number">1.3.1.</span> <span class="nav-text">2.3.1 错误率与精度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9F%A5%E5%87%86%E7%8E%87precision-%E6%9F%A5%E5%85%A8%E7%8E%87recall-f1"><span class="nav-number">1.3.2.</span> <span class="nav-text">2.3.2 查准率(Precision),
查全率(Recall), F1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#roc%E4%B8%8Eauc"><span class="nav-number">1.3.3.</span> <span class="nav-text">2.3.3 ROC与AUC</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BB%A3%E4%BB%B7%E6%95%8F%E6%84%9F%E9%94%99%E8%AF%AF%E7%8E%87%E4%B8%8E%E4%BB%A3%E4%BB%B7%E6%9B%B2%E7%BA%BF"><span class="nav-number">1.3.4.</span> <span class="nav-text">2.3.4 代价敏感错误率与代价曲线</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%AF%94%E8%BE%83%E6%A3%80%E9%AA%8C"><span class="nav-number">1.4.</span> <span class="nav-text">2.4 比较检验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C"><span class="nav-number">1.4.1.</span> <span class="nav-text">2.4.1 假设检验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%A4%9A%E5%AD%A6%E4%B9%A0%E5%99%A8%E6%AF%94%E8%BE%83"><span class="nav-number">1.4.2.</span> <span class="nav-text">2.4.2 多学习器比较</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE"><span class="nav-number">1.5.</span> <span class="nav-text">2.5 偏差与方差</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LaPluma"
      src="/images/hikari_tairitsu/avatar.jpg">
  <p class="site-author-name" itemprop="name">LaPluma</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">26</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/La-Pluma" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;La-Pluma" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:baixingluo0114@gmail.com" title="E-Mail → mailto:baixingluo0114@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <!--
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  -->
  <span class="author" itemprop="copyrightHolder">LaPluma</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">133k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">4:02</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

<!--

-->

        
<div class="busuanzi-count">
  <script data-pjax async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: inline;">
    <!--<span class="post-meta-item">-->
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: inline;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/pjax/pjax.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>

  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  




  
<script src="/js/local-search.js"></script>













    <div id="pjax">
  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '24px',
  right: 'unset',
  left: '24px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#444',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : 'Ov23liouFxqnH4lyyruL',
      clientSecret: '63c3d5092e75ac897fea78ade59a03c33b607595',
      repo        : 'la-pluma.github.io',
      owner       : 'La-Pluma',
      admin       : ['La-Pluma'],
      id          : 'd3309156d0c4131327baebc574042667',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

    </div>
</body>
</html>
